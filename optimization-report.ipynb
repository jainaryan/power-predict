{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:15:50.976113400Z",
     "start_time": "2023-11-01T05:15:49.271371200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "import matplotlib\n",
    "from matplotlib.patches import Polygon, Rectangle\n",
    "matplotlib.use('Qt5Agg')\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from casadi import *\n",
    "import calendar\n",
    "import casadi as cd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "        Month         MW\n0  2022-01-01  1415.4246\n1  2022-02-01  1353.4260\n2  2022-03-01  2254.4145\n3  2022-04-01  2269.1010\n4  2022-05-01  2690.4150\n5  2022-06-01  2708.4910\n6  2022-07-01  3113.6625\n7  2022-08-01  3606.0495\n8  2022-09-01  3335.3190\n9  2022-10-01  2787.5835\n10 2022-11-01  2230.0764\n11 2022-12-01  1809.5913\n12 2023-01-01  1859.8434\n13 2023-02-01  1829.5317\n14 2023-03-01  2238.3650\n15 2023-04-01  2615.2850\n16 2023-05-01        NaN\n17 2023-06-01  3112.0245\n18 2023-07-01  3376.0350\n19 2023-08-01  3896.1580",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Month</th>\n      <th>MW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-01-01</td>\n      <td>1415.4246</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-02-01</td>\n      <td>1353.4260</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-03-01</td>\n      <td>2254.4145</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-04-01</td>\n      <td>2269.1010</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-05-01</td>\n      <td>2690.4150</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2022-06-01</td>\n      <td>2708.4910</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2022-07-01</td>\n      <td>3113.6625</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2022-08-01</td>\n      <td>3606.0495</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2022-09-01</td>\n      <td>3335.3190</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2022-10-01</td>\n      <td>2787.5835</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2022-11-01</td>\n      <td>2230.0764</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2022-12-01</td>\n      <td>1809.5913</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2023-01-01</td>\n      <td>1859.8434</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2023-02-01</td>\n      <td>1829.5317</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2023-03-01</td>\n      <td>2238.3650</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2023-04-01</td>\n      <td>2615.2850</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2023-05-01</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2023-06-01</td>\n      <td>3112.0245</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2023-07-01</td>\n      <td>3376.0350</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2023-08-01</td>\n      <td>3896.1580</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "        Month  Number of units of electricity consumed         MW\n0  2022-01-01                                1415424.6  1415.4246\n1  2022-02-01                                1353426.0  1353.4260\n2  2022-03-01                                2254414.5  2254.4145\n3  2022-04-01                                2269101.0  2269.1010\n4  2022-05-01                                2690415.0  2690.4150\n5  2022-06-01                                2708491.0  2708.4910\n6  2022-07-01                                3113662.5  3113.6625\n7  2022-08-01                                3606049.5  3606.0495\n8  2022-09-01                                3335319.0  3335.3190\n9  2022-10-01                                2787583.5  2787.5835\n10 2022-11-01                                2230076.4  2230.0764\n11 2022-12-01                                1809591.3  1809.5913\n12 2023-01-01                                1859843.4  1859.8434\n13 2023-02-01                                1829531.7  1829.5317\n14 2023-03-01                                2238365.0  2238.3650\n15 2023-04-01                                2615285.0  2615.2850\n16 2023-05-01                                      NaN        NaN\n17 2023-06-01                                3112024.5  3112.0245\n18 2023-07-01                                3376035.0  3376.0350\n19 2023-08-01                                3896158.0  3896.1580",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Month</th>\n      <th>Number of units of electricity consumed</th>\n      <th>MW</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2022-01-01</td>\n      <td>1415424.6</td>\n      <td>1415.4246</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2022-02-01</td>\n      <td>1353426.0</td>\n      <td>1353.4260</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2022-03-01</td>\n      <td>2254414.5</td>\n      <td>2254.4145</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2022-04-01</td>\n      <td>2269101.0</td>\n      <td>2269.1010</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2022-05-01</td>\n      <td>2690415.0</td>\n      <td>2690.4150</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2022-06-01</td>\n      <td>2708491.0</td>\n      <td>2708.4910</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2022-07-01</td>\n      <td>3113662.5</td>\n      <td>3113.6625</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2022-08-01</td>\n      <td>3606049.5</td>\n      <td>3606.0495</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>2022-09-01</td>\n      <td>3335319.0</td>\n      <td>3335.3190</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>2022-10-01</td>\n      <td>2787583.5</td>\n      <td>2787.5835</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>2022-11-01</td>\n      <td>2230076.4</td>\n      <td>2230.0764</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2022-12-01</td>\n      <td>1809591.3</td>\n      <td>1809.5913</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>2023-01-01</td>\n      <td>1859843.4</td>\n      <td>1859.8434</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>2023-02-01</td>\n      <td>1829531.7</td>\n      <td>1829.5317</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>2023-03-01</td>\n      <td>2238365.0</td>\n      <td>2238.3650</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>2023-04-01</td>\n      <td>2615285.0</td>\n      <td>2615.2850</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2023-05-01</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>2023-06-01</td>\n      <td>3112024.5</td>\n      <td>3112.0245</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>2023-07-01</td>\n      <td>3376035.0</td>\n      <td>3376.0350</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2023-08-01</td>\n      <td>3896158.0</td>\n      <td>3896.1580</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_date_parser(date_string):\n",
    "    return pd.to_datetime(date_string, format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "# Specify the path to the main directory containing folders and files\n",
    "path = 'D:\\\\mlinternship\\\\iitgdata'\n",
    "folders = [folder for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder))]\n",
    "df_list = []\n",
    "\n",
    "# Iterate through each folder\n",
    "for folder in folders:\n",
    "    # Construct the full path to the current folder\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    # Iterate through files in the current folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file has the '.xlsx' extension\n",
    "        if filename.endswith('.xlsx'):\n",
    "            # Construct the full path to the Excel file\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Use the custom date parser function\n",
    "            df = pd.read_excel(file_path, header=3, date_parser=custom_date_parser)\n",
    "            # Append the dataframe to the list\n",
    "            df_list.append(df)\n",
    "\n",
    "bill_path = 'D:\\\\mlinternship\\\\IITGuwahatiElectricityBills'\n",
    "for filename in os.listdir(bill_path):\n",
    "    # Check if the file has the '.xlsx' extension\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(bill_path, filename)\n",
    "        bill_df = pd.read_excel(file_path)\n",
    "\n",
    "bill_df['Month'] = pd.to_datetime(bill_df['Month'])\n",
    "#I assumed its in kilowatts\n",
    "bill_df['MW'] = bill_df['Number of units of electricity consumed']/1000\n",
    "bill_df.drop(['Number of units of electricity consumed'], axis=1)\n",
    "bill_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:15:59.948547Z",
     "start_time": "2023-11-01T05:15:50.976113400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "      temperature                Time\n0            22.0 2023-05-03 00:00:00\n1            22.3 2023-05-03 00:15:00\n2            22.5 2023-05-03 00:30:00\n3            23.2 2023-05-03 00:45:00\n4            23.1 2023-05-03 01:00:00\n...           ...                 ...\n3962         26.0 2023-06-22 22:45:00\n3963         26.0 2023-06-22 23:00:00\n3964         26.0 2023-06-22 23:15:00\n3965         26.0 2023-06-22 23:30:00\n3966         26.1 2023-06-22 23:45:00\n\n[3967 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>temperature</th>\n      <th>Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>22.0</td>\n      <td>2023-05-03 00:00:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>22.3</td>\n      <td>2023-05-03 00:15:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>22.5</td>\n      <td>2023-05-03 00:30:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.2</td>\n      <td>2023-05-03 00:45:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23.1</td>\n      <td>2023-05-03 01:00:00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3962</th>\n      <td>26.0</td>\n      <td>2023-06-22 22:45:00</td>\n    </tr>\n    <tr>\n      <th>3963</th>\n      <td>26.0</td>\n      <td>2023-06-22 23:00:00</td>\n    </tr>\n    <tr>\n      <th>3964</th>\n      <td>26.0</td>\n      <td>2023-06-22 23:15:00</td>\n    </tr>\n    <tr>\n      <th>3965</th>\n      <td>26.0</td>\n      <td>2023-06-22 23:30:00</td>\n    </tr>\n    <tr>\n      <th>3966</th>\n      <td>26.1</td>\n      <td>2023-06-22 23:45:00</td>\n    </tr>\n  </tbody>\n</table>\n<p>3967 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_data_path = 'D:\\\\mlinternship\\\\iitgdata\\\\temperaturedata\\\\report'\n",
    "temperature_df_list = []\n",
    "for filename in os.listdir(temperature_data_path):\n",
    "        # Check if the file has the '.xlsx' extension\n",
    "        if filename.endswith('.xlsx'):\n",
    "            # Construct the full path to the Excel file\n",
    "            file_path = os.path.join(temperature_data_path, filename)\n",
    "            # Use the custom date parser function\n",
    "            df = pd.read_excel(file_path, header=18, date_parser=custom_date_parser)\n",
    "            df = df[['DATE(YYYY-MM-DD)', 'TIME (UTC)', \"TEMP. ('C)\"]]\n",
    "            # Append the dataframe to the list\n",
    "            temperature_df_list.append(df)\n",
    "temperature_df = pd.concat(temperature_df_list, ignore_index=True)\n",
    "temperature_df['Time'] = pd.to_datetime(temperature_df['DATE(YYYY-MM-DD)'] + ' ' + temperature_df['TIME (UTC)'])\n",
    "# Rename the 'TEMP. ('C)' column to 'temperature'\n",
    "temperature_df.rename(columns={\"TEMP. ('C)\": 'temperature'}, inplace=True)\n",
    "# Drop the 'DATE(YYYY-MM-DD)' and 'TIME (UTC)' columns from temperature_df\n",
    "temperature_df = temperature_df.drop(['DATE(YYYY-MM-DD)', 'TIME (UTC)'], axis=1)\n",
    "temperature_df = temperature_df.sort_values(by='Time')\n",
    "temperature_df.reset_index(drop = True, inplace = True)\n",
    "temperature_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:16:01.613009900Z",
     "start_time": "2023-11-01T05:15:59.952583200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ntemperature_data_csv_path = 'D:\\\\mlinternship\\\\iitgdata\\\\temperaturedata'\\nfilename = 'guwahati_temperature_data.csv'\\nfile = os.path.join(temperature_data_csv_path, filename)\\ntemperature_df = pd.read_csv(file)\\ntemperature_df.rename(columns={'valid': 'Time'}, inplace = True)\\ntemperature_df = temperature_df.rename(columns={'tmpc': 'temperature'})\\ntemperature_df = temperature_df[['Time', 'temperature']]\\ntemperature_df['Time'] = pd.to_datetime(temperature_df['Time'])\\ntemperature_df['Time'] = pd.DatetimeIndex(temperature_df['Time']) + timedelta(hours=5,minutes=30)\\ntemperature_df['temperature'] = pd.to_numeric(temperature_df['temperature'], errors='coerce')\\ntemperature_df.set_index('Time', inplace=True)\\ntemperature_df['temperature'] = temperature_df['temperature'].interpolate(method='polynomial', order = 5)\\ntemperature_df.reset_index(inplace=True)\\n\""
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "                    Time   MW  temperature\n0    2023-05-03 00:00:00  3.0         22.0\n1    2023-05-03 01:00:00  NaN         23.1\n2    2023-05-03 02:00:00  NaN         25.8\n3    2023-05-03 03:00:00  2.5         27.8\n4    2023-05-03 04:00:00  NaN         29.5\n...                  ...  ...          ...\n1004 2023-06-13 19:00:00  5.7          NaN\n1005 2023-06-13 20:00:00  5.8          NaN\n1006 2023-06-13 21:00:00  5.5          NaN\n1007 2023-06-13 22:00:00  5.0          NaN\n1008 2023-06-13 23:00:00  5.0          NaN\n\n[1009 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>MW</th>\n      <th>temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-05-03 00:00:00</td>\n      <td>3.0</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-05-03 01:00:00</td>\n      <td>NaN</td>\n      <td>23.1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-05-03 02:00:00</td>\n      <td>NaN</td>\n      <td>25.8</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-05-03 03:00:00</td>\n      <td>2.5</td>\n      <td>27.8</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-05-03 04:00:00</td>\n      <td>NaN</td>\n      <td>29.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1004</th>\n      <td>2023-06-13 19:00:00</td>\n      <td>5.7</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1005</th>\n      <td>2023-06-13 20:00:00</td>\n      <td>5.8</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1006</th>\n      <td>2023-06-13 21:00:00</td>\n      <td>5.5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1007</th>\n      <td>2023-06-13 22:00:00</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1008</th>\n      <td>2023-06-13 23:00:00</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1009 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "                    Time   MW  temperature\n7175 2023-05-03 00:00:00  3.0         22.0\n7176 2023-05-03 01:00:00  NaN         23.1\n7177 2023-05-03 02:00:00  NaN         25.8\n7178 2023-05-03 03:00:00  2.5         27.8\n7179 2023-05-03 04:00:00  NaN         29.5\n...                  ...  ...          ...\n8179 2023-06-13 19:00:00  5.7          NaN\n8180 2023-06-13 20:00:00  5.8          NaN\n8181 2023-06-13 21:00:00  5.5          NaN\n8182 2023-06-13 22:00:00  5.0          NaN\n8183 2023-06-13 23:00:00  5.0          NaN\n\n[1009 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>MW</th>\n      <th>temperature</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7175</th>\n      <td>2023-05-03 00:00:00</td>\n      <td>3.0</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>7176</th>\n      <td>2023-05-03 01:00:00</td>\n      <td>NaN</td>\n      <td>23.1</td>\n    </tr>\n    <tr>\n      <th>7177</th>\n      <td>2023-05-03 02:00:00</td>\n      <td>NaN</td>\n      <td>25.8</td>\n    </tr>\n    <tr>\n      <th>7178</th>\n      <td>2023-05-03 03:00:00</td>\n      <td>2.5</td>\n      <td>27.8</td>\n    </tr>\n    <tr>\n      <th>7179</th>\n      <td>2023-05-03 04:00:00</td>\n      <td>NaN</td>\n      <td>29.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>8179</th>\n      <td>2023-06-13 19:00:00</td>\n      <td>5.7</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8180</th>\n      <td>2023-06-13 20:00:00</td>\n      <td>5.8</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8181</th>\n      <td>2023-06-13 21:00:00</td>\n      <td>5.5</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8182</th>\n      <td>2023-06-13 22:00:00</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>8183</th>\n      <td>2023-06-13 23:00:00</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1009 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the power data\n",
    "power_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'])\n",
    "power_df['Time'] = power_df['Time'].round('min')\n",
    "#replace all the 'NR' values in MW column to NaN\n",
    "power_df['MW'] = power_df['MW'].replace('NR', np.nan)\n",
    "power_df['MW'] = power_df['MW'].replace('nr', np.nan)\n",
    "power_df = power_df[['Time', 'MW']]\n",
    "power_df['MW'] = power_df['MW'].astype(str)\n",
    "power_df['MW'] = pd.to_numeric(power_df['MW'].str.replace(',', '.'), errors='coerce')\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'])\n",
    "power_df = power_df.sort_values('Time')\n",
    "power_df.to_csv('power_datacsv.csv')\n",
    "full_power_df = power_df.copy()\n",
    "\n",
    "# read the temperature data csv\n",
    "'''\n",
    "temperature_data_csv_path = 'D:\\\\mlinternship\\\\iitgdata\\\\temperaturedata'\n",
    "filename = 'guwahati_temperature_data.csv'\n",
    "file = os.path.join(temperature_data_csv_path, filename)\n",
    "temperature_df = pd.read_csv(file)\n",
    "temperature_df.rename(columns={'valid': 'Time'}, inplace = True)\n",
    "temperature_df = temperature_df.rename(columns={'tmpc': 'temperature'})\n",
    "temperature_df = temperature_df[['Time', 'temperature']]\n",
    "temperature_df['Time'] = pd.to_datetime(temperature_df['Time'])\n",
    "temperature_df['Time'] = pd.DatetimeIndex(temperature_df['Time']) + timedelta(hours=5,minutes=30)\n",
    "temperature_df['temperature'] = pd.to_numeric(temperature_df['temperature'], errors='coerce')\n",
    "temperature_df.set_index('Time', inplace=True)\n",
    "temperature_df['temperature'] = temperature_df['temperature'].interpolate(method='polynomial', order = 5)\n",
    "temperature_df.reset_index(inplace=True)\n",
    "'''\n",
    "# joining the two dataframes such that the temperature data is only taken if there exists a reading in the power data dataframe\n",
    "df = pd.merge(power_df, temperature_df, on='Time', how='left')\n",
    "df['temperature'] = df['temperature'].interpolate(method='polynomial', order = 5)\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "full_model_start_time = pd.Timestamp('2023-05-03 00:00:00')\n",
    "full_model_end_time = pd.Timestamp('2023-06-13 23:00:00')\n",
    "df = df[(df['Time'] >= full_model_start_time) & (df['Time'] <= full_model_end_time)]\n",
    "df = df.drop(df[df['MW'] > 20].index)\n",
    "df = df.sort_values('Time')\n",
    "df.reset_index(drop=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:16:02.650697900Z",
     "start_time": "2023-11-01T05:16:01.613009900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                   Time    MW temperature  CDH omega1 omega2 omega3 omega4  \\\n0   2023-05-03 00:00:00   3.0        22.0  0.0    0.0    0.0    0.0    0.0   \n1   2023-05-03 03:00:00   2.5        27.8  0.0    0.0    0.0    0.0    0.0   \n2   2023-05-03 05:00:00   3.0        31.5  0.5    0.0    0.0    0.0    0.0   \n3   2023-05-03 06:00:00   3.5        33.1  2.1    0.0    0.0    0.0    0.0   \n4   2023-05-03 07:00:00  3.75        29.3  0.0    0.0    0.0    0.0    0.0   \n..                  ...   ...         ...  ...    ...    ...    ...    ...   \n650 2023-06-07 07:00:00   4.7        38.9  7.9    0.0    0.0    0.0    0.0   \n651 2023-06-07 08:00:00   4.9        39.0  8.0    0.0    0.0    0.0    0.0   \n652 2023-06-07 09:00:00   4.8        39.2  8.2    0.0    0.0    0.0    0.0   \n653 2023-06-07 10:00:00   5.6        38.0  7.0    0.0    0.0    0.0    0.0   \n654 2023-06-07 11:00:00   6.0        35.0  4.0    0.0    0.0    0.0    0.0   \n\n    omega5 omega6  ... omega159 omega160 omega161 omega162 omega163 omega164  \\\n0      0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n1      0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n2      0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n3      0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n4      0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n..     ...    ...  ...      ...      ...      ...      ...      ...      ...   \n650    0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n651    0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n652    0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n653    0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n654    0.0    0.0  ...      0.0      0.0      0.0      0.0      0.0      0.0   \n\n    omega165 omega166 omega167 omega168  \n0        0.0      0.0      0.0      0.0  \n1        0.0      0.0      0.0      0.0  \n2        0.0      0.0      0.0      0.0  \n3        0.0      0.0      0.0      0.0  \n4        0.0      0.0      0.0      0.0  \n..       ...      ...      ...      ...  \n650      0.0      0.0      0.0      0.0  \n651      0.0      0.0      0.0      0.0  \n652      0.0      0.0      0.0      0.0  \n653      0.0      0.0      0.0      0.0  \n654      0.0      0.0      0.0      0.0  \n\n[655 rows x 172 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>MW</th>\n      <th>temperature</th>\n      <th>CDH</th>\n      <th>omega1</th>\n      <th>omega2</th>\n      <th>omega3</th>\n      <th>omega4</th>\n      <th>omega5</th>\n      <th>omega6</th>\n      <th>...</th>\n      <th>omega159</th>\n      <th>omega160</th>\n      <th>omega161</th>\n      <th>omega162</th>\n      <th>omega163</th>\n      <th>omega164</th>\n      <th>omega165</th>\n      <th>omega166</th>\n      <th>omega167</th>\n      <th>omega168</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-05-03 00:00:00</td>\n      <td>3.0</td>\n      <td>22.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-05-03 03:00:00</td>\n      <td>2.5</td>\n      <td>27.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-05-03 05:00:00</td>\n      <td>3.0</td>\n      <td>31.5</td>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-05-03 06:00:00</td>\n      <td>3.5</td>\n      <td>33.1</td>\n      <td>2.1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-05-03 07:00:00</td>\n      <td>3.75</td>\n      <td>29.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>650</th>\n      <td>2023-06-07 07:00:00</td>\n      <td>4.7</td>\n      <td>38.9</td>\n      <td>7.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>651</th>\n      <td>2023-06-07 08:00:00</td>\n      <td>4.9</td>\n      <td>39.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>652</th>\n      <td>2023-06-07 09:00:00</td>\n      <td>4.8</td>\n      <td>39.2</td>\n      <td>8.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>653</th>\n      <td>2023-06-07 10:00:00</td>\n      <td>5.6</td>\n      <td>38.0</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>654</th>\n      <td>2023-06-07 11:00:00</td>\n      <td>6.0</td>\n      <td>35.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>655 rows × 172 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TcoolStPt = 31\n",
    "CDH = df['temperature'] - TcoolStPt\n",
    "CDH.clip(lower=0, inplace=True)\n",
    "CDH = pd.DataFrame(data=CDH.values, columns=['CDH'], index=df.index)\n",
    "# Concatenate CDH with the original DataFrame using the index\n",
    "df = pd.concat([df, CDH], axis=1)\n",
    "df = df.sort_values('Time')\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "\n",
    "numOmegas = 24 * 7\n",
    "num_of_rows = df.shape[0]\n",
    "omegas = np.zeros((num_of_rows, numOmegas))  # Assuming numOmegas columns for omegas\n",
    "concatenated_data = np.concatenate((df, omegas), axis=1)\n",
    "column_names = ['Time', 'MW', 'temperature', 'CDH']\n",
    "for i in range(1, numOmegas + 1,1):\n",
    "    column_names.append('omega' + str(i))\n",
    "\n",
    "df = pd.DataFrame(concatenated_data, columns=column_names)\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "for i in range(0,num_of_rows):\n",
    "        datetime = df.Time.loc[i]\n",
    "        hourOfWeekIndex = int(datetime.dayofweek*24+(datetime.hour+1))\n",
    "        x = np.zeros((1,numOmegas))\n",
    "        x[0,hourOfWeekIndex-1]=1\n",
    "        omegas[i,:]=x\n",
    "\n",
    "df.iloc[:,4:]=omegas\n",
    "DF = df.copy()\n",
    "df = df.dropna()\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:16:02.947710400Z",
     "start_time": "2023-11-01T05:16:02.618695600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******************************************************************************\n",
      "This program contains Ipopt, a library for large-scale nonlinear optimization.\n",
      " Ipopt is released as open source code under the Eclipse Public License (EPL).\n",
      "         For more information visit https://github.com/coin-or/Ipopt\n",
      "******************************************************************************\n",
      "\n",
      "This is Ipopt version 3.14.11, running with linear solver MUMPS 5.4.1.\n",
      "\n",
      "Number of nonzeros in equality constraint Jacobian...:        0\n",
      "Number of nonzeros in inequality constraint Jacobian.:     2337\n",
      "Number of nonzeros in Lagrangian Hessian.............:    14365\n",
      "\n",
      "Total number of variables............................:      169\n",
      "                     variables with only lower bounds:        0\n",
      "                variables with lower and upper bounds:        0\n",
      "                     variables with only upper bounds:        0\n",
      "Total number of equality constraints.................:        0\n",
      "Total number of inequality constraints...............:     1003\n",
      "        inequality constraints with only lower bounds:      502\n",
      "   inequality constraints with lower and upper bounds:        0\n",
      "        inequality constraints with only upper bounds:      501\n",
      "\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "   0  1.3367039e+04 3.63e+02 5.05e-01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0\n",
      "   1  1.0710353e+04 0.00e+00 4.47e+01  -1.0 5.88e+01    -  2.17e-02 1.00e+00f  1\n",
      "   2  9.9245988e+03 0.00e+00 8.63e-01  -1.0 3.75e-01    -  5.23e-01 1.00e+00f  1\n",
      "   3  4.5329134e+03 0.00e+00 6.53e-01  -1.0 3.43e+00    -  1.91e-01 1.00e+00f  1\n",
      "   4  1.7217870e+03 0.00e+00 4.33e-01  -1.0 9.79e+00    -  2.14e-01 1.00e+00f  1\n",
      "   5  5.0222524e+02 0.00e+00 1.11e+00  -1.0 3.90e+01    -  7.41e-01 1.00e+00f  1\n",
      "   6  1.9601222e+02 0.00e+00 1.04e-01  -1.0 9.66e+00    -  9.47e-01 1.00e+00f  1\n",
      "   7  1.6710832e+02 0.00e+00 1.00e-06  -1.0 6.07e+00    -  1.00e+00 1.00e+00f  1\n",
      "   8  1.5341082e+02 0.00e+00 2.00e-07  -1.7 8.16e-01    -  1.00e+00 1.00e+00f  1\n",
      "   9  1.4831397e+02 0.00e+00 3.70e-02  -3.8 1.05e+00    -  7.82e-01 1.00e+00f  1\n",
      "iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls\n",
      "  10  1.4732108e+02 0.00e+00 1.72e-03  -3.8 8.42e-01    -  9.60e-01 1.00e+00f  1\n",
      "  11  1.4714357e+02 0.00e+00 1.50e-09  -3.8 3.64e-01    -  1.00e+00 1.00e+00f  1\n",
      "  12  1.4710014e+02 0.00e+00 1.02e-05  -5.7 1.25e-01    -  9.91e-01 1.00e+00f  1\n",
      "  13  1.4709618e+02 0.00e+00 1.84e-11  -5.7 5.96e-02    -  1.00e+00 1.00e+00f  1\n",
      "  14  1.4709528e+02 0.00e+00 1.84e-11  -5.7 4.32e-02    -  1.00e+00 1.00e+00f  1\n",
      "  15  1.4709486e+02 0.00e+00 4.24e-06  -8.6 6.53e-03    -  1.00e+00 9.77e-01f  1\n",
      "  16  1.4709479e+02 0.00e+00 2.51e-14  -8.6 1.50e-03    -  1.00e+00 1.00e+00f  1\n",
      "  17  1.4709479e+02 0.00e+00 2.51e-14  -8.6 4.24e-04    -  1.00e+00 1.00e+00h  1\n",
      "\n",
      "Number of Iterations....: 17\n",
      "\n",
      "                                   (scaled)                 (unscaled)\n",
      "Objective...............:   2.7713133436520088e+00    1.4709478870262393e+02\n",
      "Dual infeasibility......:   2.5059815333960955e-14    1.3301160079639953e-12\n",
      "Constraint violation....:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00\n",
      "Complementarity.........:   2.6688125814648458e-09    1.4165428952907689e-07\n",
      "Overall NLP error.......:   2.6688125814648458e-09    1.4165428952907689e-07\n",
      "\n",
      "\n",
      "Number of objective function evaluations             = 18\n",
      "Number of objective gradient evaluations             = 18\n",
      "Number of equality constraint evaluations            = 0\n",
      "Number of inequality constraint evaluations          = 18\n",
      "Number of equality constraint Jacobian evaluations   = 0\n",
      "Number of inequality constraint Jacobian evaluations = 18\n",
      "Number of Lagrangian Hessian evaluations             = 17\n",
      "Total seconds in IPOPT                               = 2.001\n",
      "\n",
      "EXIT: Optimal Solution Found.\n",
      "Optimal value of temperature_theta: 0.13359730050658533\n",
      "Optimal values of theta: [3.48000002 4.06999998 3.826207   3.57324096 3.92467572 4.2011255\n",
      " 3.44013347 3.67547734 3.70467577 3.60066287 4.29906112 4.41624432\n",
      " 4.77966344 5.012401   4.89       4.95       5.21999999 5.21999999\n",
      " 5.08       4.92       4.86       4.85999999 4.77500001 4.99999997\n",
      " 4.42500001 4.24999996 3.54484162 3.00000004 3.29596716 3.75912889\n",
      " 3.74910275 3.79508139 3.72965832 4.04164247 4.33370582 4.44333481\n",
      " 4.9663235  5.13999999 4.85       5.28       5.82499998 5.71249999\n",
      " 5.52       5.57499999 5.225      4.99999999 4.7        4.69999998\n",
      " 3.86364861 4.74202691 2.62040573 3.49878129 3.21526805 2.84616514\n",
      " 3.60480764 3.68864814 3.4945504  3.613075   4.34832575 4.5951508\n",
      " 4.43816176 4.94332012 5.144      5.28199999 5.36799999 5.39\n",
      " 5.54199999 5.59249999 5.2725     5.16999999 4.60500003 4.70999993\n",
      " 3.29000009 2.94603833 2.85117975 2.69000001 2.56808106 2.5580826\n",
      " 3.47875788 3.67010742 3.63794793 3.60416851 4.3527262  4.81441853\n",
      " 4.91326073 4.65       4.78       5.04       5.27999999 5.1\n",
      " 5.06       5.09999999 4.59       4.41999999 4.03565311 3.75582889\n",
      " 3.60188137 3.53023201 3.50079628 3.48933435 3.4848425  3.48697454\n",
      " 3.50899546 3.58946151 3.86814929 4.23013345 4.59313488 4.76833934\n",
      " 4.80121718 4.81932805 4.98       5.18       5.43999999 5.47999999\n",
      " 5.27499999 5.15       5.11999999 4.76       4.45       4.39999999\n",
      " 3.9        3.20000001 3.05       2.84656108 2.72632351 2.69074206\n",
      " 3.4779909  3.18119227 3.05893093 2.97170583 3.35301804 3.50523978\n",
      " 3.68958425 3.93826074 4.304      4.532      4.74799999 4.728\n",
      " 5.13499999 5.0325     4.9475     4.93666665 4.46       4.25999999\n",
      " 3.75       3.20897126 2.75000001 2.7738618  2.75984875 2.68988123\n",
      " 3.04616513 3.04125962 2.92066286 2.98325561 2.9286787  2.9928054\n",
      " 3.201138   3.30664028 3.77999999 3.82       4.04       4.214\n",
      " 4.44       4.63999999 4.56       4.51000001 5.21999996 5.02000001]\n"
     ]
    }
   ],
   "source": [
    "#temperature and behavior part together\n",
    "#check starting and ending dates of week and adjust accordingly\n",
    "start_time = pd.Timestamp('2023-05-01 00:00:00')\n",
    "end_time = pd.Timestamp('2023-06-15 23:00:00')\n",
    "\n",
    "training_mask = (df['Time'] >= start_time) & (df['Time'] <= end_time)\n",
    "training_df = df[training_mask]\n",
    "d = training_df.loc[:,'MW']\n",
    "phi_temperature = training_df.loc[:,'CDH']\n",
    "phi_behavior = training_df.loc[:,'omega1':'omega168']\n",
    "opti = cd.Opti()\n",
    "temperature_theta = opti.variable()\n",
    "behavior_theta = opti.variable(168)\n",
    "total_sum =0\n",
    "for i in range (0,len(d)):\n",
    "    phi_behavior_i = (cd.MX(phi_behavior.iloc[i].values))\n",
    "    phi_behavior_i =  cd.vertcat(phi_behavior_i)\n",
    "    residual = (d.iloc[i] - ((phi_temperature.iloc[i] * temperature_theta) + cd.dot(phi_behavior_i, behavior_theta)))**2\n",
    "    total_sum += residual\n",
    "\n",
    "opti.subject_to(temperature_theta >= 0)\n",
    "e1 = 3.0\n",
    "e2 = 3.0\n",
    "\n",
    "for i in range(0, 167):\n",
    "    opti.subject_to((behavior_theta[i + 1] - behavior_theta[i]) <= e1)\n",
    "    opti.subject_to((behavior_theta[i + 1] - behavior_theta[i]) >= -e1)\n",
    "    opti.subject_to(behavior_theta[i] >= 0)\n",
    "    opti.subject_to(behavior_theta[i] <= 7)\n",
    "\n",
    "for i in range(1, 167):\n",
    "    opti.subject_to((behavior_theta[i + 1] + behavior_theta[i - 1] - 2 * behavior_theta[i]) <= e2)\n",
    "    opti.subject_to((behavior_theta[i + 1] + behavior_theta[i - 1] - 2 * behavior_theta[i]) >= -e2)\n",
    "\n",
    "#hardcoded for may-june 2023\n",
    "for i in range(16,18):\n",
    "    if pd.isna(bill_df.iloc[i]['MW']):\n",
    "        continue\n",
    "    month = bill_df.iloc[i]['Month'].month\n",
    "    year = bill_df.iloc[i]['Month'].year\n",
    "    num_days = calendar.monthrange(year, month)[1]\n",
    "    first_day = calendar.monthrange(year, month)[0]\n",
    "    num_hours = num_days * 24\n",
    "    num_weeks = num_hours / 168.0\n",
    "    weekly_behavior_energy_use = 0\n",
    "    temperature_energy_use = 0\n",
    "    for j in range(len(training_df)):\n",
    "        temperature_energy_use += temperature_theta * training_df.iloc[j]['CDH']\n",
    "\n",
    "    for j in range(0, 168):\n",
    "        weekly_behavior_energy_use += behavior_theta[j]\n",
    "\n",
    "    weekly_energy_use = weekly_behavior_energy_use +  temperature_energy_use\n",
    "    opti.subject_to(weekly_energy_use < 1.5 * bill_df.iloc[i]['MW'] / num_weeks)\n",
    "    opti.subject_to(weekly_energy_use > 0.5 * bill_df.iloc[i]['MW'] / num_weeks)\n",
    "\n",
    "# Solve the optimization problem\n",
    "opti.minimize(total_sum)\n",
    "solver_opts = {'print_time': 0}\n",
    "opti.solver('ipopt', solver_opts)\n",
    "sol = opti.solve()\n",
    "\n",
    "optimal_temperature_theta = sol.value(temperature_theta)\n",
    "optimal_behavior_theta = sol.value(behavior_theta)\n",
    "print(\"Optimal value of temperature_theta:\", optimal_temperature_theta)\n",
    "print(\"Optimal values of theta:\", optimal_behavior_theta)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:16:09.111785400Z",
     "start_time": "2023-11-01T05:16:02.707750300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression(fit_intercept=False)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(fit_intercept=False)</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score for constructed full model on full data:  0.7127170439828718\n"
     ]
    },
    {
     "data": {
      "text/plain": "Text(0.5, 1.0, 'measured vs predicted data (full constructed model) (only for non null values)')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#final model with df\n",
    "training_df = df[training_mask]\n",
    "d = training_df['MW']\n",
    "c = np.concatenate((np.array([optimal_temperature_theta]),optimal_behavior_theta),axis=0)\n",
    "phi = training_df.loc[:,'CDH':'omega168']\n",
    "full_model = LinearRegression(fit_intercept=False)\n",
    "full_model.fit(phi, d)\n",
    "full_model.coef_ = c\n",
    "full_model.intercept_ = 0\n",
    "yhat = full_model.predict(phi.values)\n",
    "full_modelScore = full_model.score(phi,d)\n",
    "cdh = training_df['CDH']\n",
    "temperature_pred = cdh * optimal_temperature_theta\n",
    "omegas = training_df.loc[:, 'omega1':'omega168']\n",
    "# Multiply each row in omegas with optimal_behavior_theta using broadcasting\n",
    "behavior_pred = []\n",
    "for i in range (len(omegas)):\n",
    "    behavior_pred.append(np.dot(omegas.iloc[i] , optimal_behavior_theta))\n",
    "print ('score for constructed full model on full data: ', full_modelScore)\n",
    "fig,(ax2) = plt.subplots(nrows=1,figsize=(10,9))\n",
    "_=ax2.plot(training_df['Time'],behavior_pred,label='behavior dependent', marker = '*')\n",
    "_=ax2.plot(training_df['Time'],temperature_pred,label='temperature dependent',marker = 's')\n",
    "_=ax2.plot(training_df['Time'],d,label='measured', marker = 'o')\n",
    "_=ax2.plot(training_df['Time'],yhat,label='predicted', marker = 'x')\n",
    "ax2.set_title('measured vs predicted data (full constructed model) (only for non null values)')\n",
    "_=ax2.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:16:44.677475200Z",
     "start_time": "2023-11-01T05:16:09.119830800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 11\u001B[0m\n\u001B[0;32m      9\u001B[0m c \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate((np\u001B[38;5;241m.\u001B[39marray([optimal_temperature_theta]),optimal_behavior_theta),axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     10\u001B[0m phi \u001B[38;5;241m=\u001B[39mtraining_df\u001B[38;5;241m.\u001B[39mloc[:,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCDH\u001B[39m\u001B[38;5;124m'\u001B[39m:\u001B[38;5;124m'\u001B[39m\u001B[38;5;124momega168\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m---> 11\u001B[0m yhat \u001B[38;5;241m=\u001B[39m \u001B[43mfull_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mphi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m actual_df \u001B[38;5;241m=\u001B[39m DF\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     13\u001B[0m actual_df \u001B[38;5;241m=\u001B[39m actual_df[training_mask]\n",
      "File \u001B[1;32mD:\\mlinternship\\power-predict\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:386\u001B[0m, in \u001B[0;36mLinearModel.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    372\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    373\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;124;03m    Predict using the linear model.\u001B[39;00m\n\u001B[0;32m    375\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;124;03m        Returns predicted values.\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_decision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\mlinternship\\power-predict\\myenv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:369\u001B[0m, in \u001B[0;36mLinearModel._decision_function\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    366\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_decision_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[0;32m    367\u001B[0m     check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m--> 369\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcoo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    370\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n",
      "File \u001B[1;32mD:\\mlinternship\\power-predict\\myenv\\Lib\\site-packages\\sklearn\\base.py:605\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    603\u001B[0m         out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    604\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[1;32m--> 605\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    606\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n\u001B[0;32m    607\u001B[0m     out \u001B[38;5;241m=\u001B[39m _check_y(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n",
      "File \u001B[1;32mD:\\mlinternship\\power-predict\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:957\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    951\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    952\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    953\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    954\u001B[0m         )\n\u001B[0;32m    956\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m--> 957\u001B[0m         \u001B[43m_assert_all_finite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    958\u001B[0m \u001B[43m            \u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    959\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    960\u001B[0m \u001B[43m            \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    961\u001B[0m \u001B[43m            \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mallow-nan\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    962\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    964\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    965\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[1;32mD:\\mlinternship\\power-predict\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:122\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    119\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m \u001B[43m_assert_all_finite_element_wise\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    123\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    124\u001B[0m \u001B[43m    \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    125\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nan\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nan\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmsg_dtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmsg_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    129\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\mlinternship\\power-predict\\myenv\\Lib\\site-packages\\sklearn\\utils\\validation.py:171\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    158\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    159\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    169\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    170\u001B[0m     )\n\u001B[1;32m--> 171\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input X contains NaN.\nLinearRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "#graph with shaded portion to represent missing values\n",
    "\n",
    "#final model with DF\n",
    "training_mask = (DF['Time'] >= start_time) & (DF['Time'] <= end_time)\n",
    "training_df = DF[training_mask]\n",
    "#actual_data = training_df['MW'].dropna()\n",
    "training_df['MW'] = training_df['MW'].replace(np.nan, 0)\n",
    "d = training_df['MW']\n",
    "c = np.concatenate((np.array([optimal_temperature_theta]),optimal_behavior_theta),axis=0)\n",
    "phi =training_df.loc[:,'CDH':'omega168']\n",
    "yhat = full_model.predict(phi.values)\n",
    "actual_df = DF.copy()\n",
    "actual_df = actual_df[training_mask]\n",
    "actual_df.dropna(inplace = True)\n",
    "\n",
    "fig10,(ax10) = plt.subplots(nrows=1,figsize=(10,9))\n",
    "first_time = True\n",
    "j = 0\n",
    "\n",
    "for i in range(1, len(training_df)):\n",
    "    if (j < len(actual_df)) and (training_df.iloc[i]['Time'] == actual_df.iloc[j]['Time']):\n",
    "        j+=1\n",
    "    else:\n",
    "        iterator = i\n",
    "        last_iterator = i-1\n",
    "        first_time= False\n",
    "        start =  mdates.date2num(training_df.iloc[last_iterator]['Time'])\n",
    "        end =  mdates.date2num(training_df.iloc[iterator]['Time'])\n",
    "        #print(f'index: {i} start:{start}, width:{end-start}')\n",
    "        rect = Rectangle((start, 0), end-start, 10, linewidth=1,  facecolor='green', alpha = 0.2, zorder = 10)\n",
    "        ax10.add_patch(rect)\n",
    "\n",
    "locator = mdates.AutoDateLocator(minticks=3)\n",
    "formatter = mdates.AutoDateFormatter(locator)\n",
    "ax10.xaxis.set_major_locator(locator)\n",
    "ax10.xaxis.set_major_formatter(formatter)\n",
    "_=ax10.plot(actual_df['Time'][training_mask],actual_df[training_mask]['MW'],label='meas', marker = 'o', color = 'r', zorder = 5)\n",
    "_=ax10.plot(training_df['Time'][training_mask],yhat,label='pred:', marker = 'x', color = 'y', zorder = 5)\n",
    "ax10.set_title('measured vs predicted data (full constructed model with NA)')\n",
    "_=ax10.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T05:17:13.666602Z",
     "start_time": "2023-11-01T05:17:13.504454300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-01T05:16:45.656428600Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
