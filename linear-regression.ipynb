{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "filepath = 'D:\\\\mlinternship\\\\iitgdata\\\\feb1-15\\\\HW_2_part_1\\\\feb-01-2022.xlsx'\n",
    "df = pd.read_excel (filepath, header = 3)\n",
    "df\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def custom_date_parser(date_string):\n",
    "    return pd.to_datetime(date_string, format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "# Specify the path to the main directory containing folders and files\n",
    "path = 'D:\\\\mlinternship\\\\iitgdata'\n",
    "folders = [folder for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder))]\n",
    "df_list = []\n",
    "\n",
    "# Iterate through each folder\n",
    "for folder in folders:\n",
    "    # Construct the full path to the current folder\n",
    "    folder_path = os.path.join(path, folder)\n",
    "\n",
    "    # Iterate through files in the current folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file has the '.xlsx' extension\n",
    "        if filename.endswith('.xlsx'):\n",
    "            # Construct the full path to the Excel file\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            # Use the custom date parser function\n",
    "            df = pd.read_excel(file_path, header=3, date_parser=custom_date_parser)\n",
    "\n",
    "            # Append the dataframe to the list\n",
    "            df_list.append(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "# adding the data from march (1-15) 2022 to the dataframe\n",
    "folder = 'D:\\\\mlinternship\\\\iitgdata\\\\mar1-15'\n",
    "\n",
    "march1_DF = []\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file = os.path.join(folder, filename)\n",
    "        march1_DF.append(pd.read_excel(file, header = 3))\n",
    "#df = pd.concat(DF, ignore_index=True)\n",
    "march1_DF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# adding the data from march (16-31) 2022 to the dataframe\n",
    "folder = 'D:\\\\mlinternship\\\\iitgdata\\\\mar16-31\\\\EE677_HW2_A_200102042'\n",
    "\n",
    "march2_DF = []\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file = os.path.join(folder, filename)\n",
    "        march2_DF.append(pd.read_excel(file, header = 3))\n",
    "#df = pd.concat(DF, ignore_index=True)\n",
    "march2_DF\n",
    "\n",
    "\n",
    "\n",
    "#preparing the dataframe with all the data from april 16-30\n",
    "folder = 'D:\\\\mlinternship\\\\iitgdata\\\\Apr16to30-2022-data 2\\\\Apr16to30-2022-data'\n",
    "\n",
    "april2_DF = []\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file = os.path.join(folder, filename)\n",
    "        april2_DF.append(pd.read_excel(file, header = 3))\n",
    "#df = pd.concat(DF, ignore_index=True)\n",
    "april2_DF\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#preparing the dataframe with all the data from june 1-15\n",
    "folder = 'D:\\\\mlinternship\\\\iitgdata\\\\june 1-15'\n",
    "\n",
    "june1_DF = []\n",
    "for filename in os.listdir(folder):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file = os.path.join(folder, filename)\n",
    "        june1_DF.append(pd.read_excel(file, header = 3))\n",
    "#df = pd.concat(DF, ignore_index=True)\n",
    "june1_DF = pd.concat(june1_DF)\n",
    "\n",
    "\n",
    "temporary_csv_path  = 'D:\\\\mlinternship\\\\iitgdata\\\\june 1-15\\\\temporary\\\\csvfile2'\n",
    "csvfile = june1_DF.to_csv(temporary_csv_path)\n",
    "june1_DF = pd.read_csv(temporary_csv_path)\n",
    "# for some reason data from june 2nd 6 am onwards is behaving strangely(6 am being read as 5:59:59.9)\n",
    "june1_DF['Time'] = pd.to_datetime(june1_DF['Time'])\n",
    "june1_DF['Time'] = june1_DF['Time'].round('min')\n",
    "june1_DF\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "power_df = pd.concat(df_list, ignore_index=True)\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'])\n",
    "power_df['Time'] = power_df['Time'].round('min')\n",
    "#replace all the 'NR' values in MW column to NaN\n",
    "power_df['MW'] = power_df['MW'].replace('NR', np.nan)\n",
    "# drop the rest of the columns that are not required and set index to Time\n",
    "power_df = power_df[['Time', 'MW']]\n",
    "\n",
    "\n",
    "power_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "power_df.dropna(subset=['Time'], inplace=True)\n",
    "power_df.set_index('Time', inplace=True)\n",
    "#converting the time column to the UTC format\n",
    "power_df.index = pd.to_datetime(power_df.index)\n",
    "\n",
    "# Convert the datetime objects to UTC timezone\n",
    "power_df.index = power_df.index.tz_localize(pytz.timezone('UTC'))\n",
    "# Now, 'Time' column is in UTC timezone format\n",
    "power_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# read the temperature data csv\n",
    "temperature_data_csv_path = 'D:\\\\mlinternship\\\\iitgdata\\\\temperaturedata'\n",
    "filename = 'guwahati_temperature_data.csv'\n",
    "file = os.path.join(temperature_data_csv_path, filename)\n",
    "temperature_df = pd.read_csv(file)\n",
    "#drop the unwanted columns and change column name\n",
    "temperature_df.rename(columns={'valid': 'Time'}, inplace = True)\n",
    "temperature_df = temperature_df.rename(columns={'tmpc': 'temperature'})\n",
    "temperature_df = temperature_df[['Time', 'temperature']]\n",
    "temperature_df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#resetting the index to prepare it to join with the power dataframe\n",
    "temperature_df.set_index('Time', inplace=True)\n",
    "temperature_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "#changing the time column to a common UTC format\n",
    "temperature_df.index = pd.to_datetime(temperature_df.index)\n",
    "\n",
    "# Convert the datetime objects to UTC timezone\n",
    "temperature_df.index = temperature_df.index.tz_localize(pytz.timezone('UTC'))\n",
    "temperature_df.index = pd.DatetimeIndex(temperature_df.index) + timedelta(hours=5,minutes=30)\n",
    "# Now, 'Time' column is in UTC timezone format\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.ion()\n",
    "plt.plot(temperature_df.index, temperature_df['temperature'], marker='o', linestyle='-', color='r', label='MW')\n",
    "\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('white')\n",
    "ax.set_title(' temperature vs time')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temperature_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# joining the two dataframes such that the temperature data is only taken if there exists a reading in the power data dataframe\n",
    "df = pd.merge(power_df, temperature_df, on='Time', how='left')\n",
    "\n",
    "DF = df.copy()\n",
    "#drop all the rows where NaN\n",
    "df.dropna(inplace = True)\n",
    "df = df.sort_index(ascending=True)\n",
    "df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df['temperature'] = pd.to_numeric(df['temperature'], errors='coerce')\n",
    "\n",
    "# Rest of your code for CDH calculation\n",
    "TcoolStPt = 31\n",
    "CDH = df['temperature'] - TcoolStPt\n",
    "CDH.clip(lower=0, inplace=True)\n",
    "CDH = pd.DataFrame(data=CDH.values, columns=['CDH'], index=df.index)\n",
    "\n",
    "CDH.index = df.index\n",
    "\n",
    "# Perform the left join without creating an extra column\n",
    "df.reset_index(drop=False, inplace=True)\n",
    "\n",
    "# Reset the index of CDH DataFrame\n",
    "CDH.reset_index(drop=False, inplace=True)\n",
    "\n",
    "\n",
    "df = pd.concat([df, CDH['CDH']], axis=1)\n",
    "df.set_index('Time', inplace = True)\n",
    "\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['MW'] = df['MW'].astype(str)\n",
    "\n",
    "# Remove commas from 'CDH' column and convert to numeric\n",
    "df['MW'] = pd.to_numeric(df['MW'].str.replace(',', '.'), errors='coerce')\n",
    "\n",
    "# Check if there are any other non-numeric values in the 'CDH' column\n",
    "non_numeric_cdh = df['MW'][pd.to_numeric(df['MW'], errors='coerce').isnull()]\n",
    "\n",
    "CDHmask = (df['CDH'] > 0)\n",
    "f,ax = plt.subplots(nrows=1, figsize = (20,8))\n",
    "_=ax.scatter(df['CDH'][CDHmask],df['MW'][CDHmask],label='vs. cooling degree hour')\n",
    "_ = ax.set_title('Scatter Plot: MW vs. Cooling Degree Hour')\n",
    "_=ax.legend()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "df.index = pd.to_datetime(df.index)\n",
    "f,ax = plt.subplots(figsize=(30,6))\n",
    "plt.plot(df.index,df['temperature'])\n",
    "plt.scatter(df.index,df['temperature'],color='red')\n",
    "ax.set_title('Temperature Over Time')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "df['MW'] = pd.to_numeric(df['MW'], errors = 'coerce')\n",
    "f,ax = plt.subplots(nrows = 1, figsize=(5,5))\n",
    "#plt.plot(df['temperature'], df['MW'])\n",
    "plt.scatter(df['temperature'], df['MW'],color='red')\n",
    "ax.set_title('MW vs Temperature')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[df['MW'] <= 20]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#temporary_df = df.dropna(subset=['temperature', 'MW'])\n",
    "\n",
    "start_time = '2002-06-01 00:00:00+00:00'\n",
    "end_time  = '2024-10-15 23:00:00+00:00'\n",
    "\n",
    "mask = (df.index >= start_time) & (df.index <= end_time)\n",
    "time_mask = df[mask]\n",
    "time_mask = time_mask.dropna(subset=['temperature', 'MW'])\n",
    "\n",
    "# Plot 'MW' against the index of time_mask\n",
    "# Create a scatter plot for y_train against x_train\n",
    "power_normalized = preprocessing.normalize([time_mask['MW']]).reshape(-1,1)\n",
    "temperature_normalized = preprocessing.normalize([time_mask['temperature']]).reshape(-1,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.ion()\n",
    "plt.plot(time_mask.index, time_mask['MW'], marker='o', linestyle='-', color='r', label='MW')\n",
    "plt.plot(time_mask.index, time_mask['temperature'], marker='o', linestyle='-', color='y', label='temp')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('white')\n",
    "ax.set_title('power and temperature vs time (not normalized)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.ion()\n",
    "plt.plot(time_mask.index, power_normalized, marker='o', linestyle='-', color='r', label='MW')\n",
    "plt.plot(time_mask.index, temperature_normalized, marker='o', linestyle='-', color='y', label='temp')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_facecolor('white')\n",
    "ax.set_title('power and temperature vs time (normalized)')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "6"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "numOmegas = 24 * 7\n",
    "\n",
    "df = df.reset_index(drop=False)\n",
    "\n",
    "num_of_rows = df.shape[0]\n",
    "omegas = np.zeros((num_of_rows, numOmegas))  # Assuming numOmegas columns for omegas\n",
    "concatenated_data = np.concatenate((df, omegas), axis=1)\n",
    "\n",
    "\n",
    "column_names = ['Time', 'MW', 'Temperature', 'CDH']\n",
    "for i in range(1, numOmegas + 1,1):\n",
    "    column_names.append('omega' + str(i))\n",
    "\n",
    "df = pd.DataFrame(concatenated_data, columns=column_names)\n",
    "df['Time'] = pd.to_datetime(df['Time'])  # Convert 'Time' column to datetime if needed\n",
    "df = df.set_index('Time')\n",
    "\n",
    "for i in range(0,num_of_rows):\n",
    "        datetime = df.index[i]\n",
    "        hourOfWeekIndex = int(datetime.dayofweek*24+(datetime.hour+1))\n",
    "        x = np.zeros((1,numOmegas))\n",
    "        x[0,hourOfWeekIndex-1]=1\n",
    "        omegas[i,:]=x\n",
    "\n",
    "\n",
    "df.iloc[:,3:]=omegas\n",
    "df\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "df.reset_index(inplace=True)\n",
    "start_time = pd.Timestamp('2022-07-14 00:00:00+00:00')\n",
    "end_time = pd.Timestamp('2022-08-30 23:00:00+00:00')\n",
    "training_mask = (df['Time'] >= start_time) & (df['Time'] <= end_time) & (df['CDH'] > 0)\n",
    "\n",
    "filtered_df = df[training_mask]\n",
    "\n",
    "filtered_df = filtered_df.dropna(subset=['CDH'])\n",
    "\n",
    "filtered_df = filtered_df.dropna(subset=['MW'])\n",
    "# Now, filtered_df contains only the rows where 'Temperature' is not NaN\n",
    "\n",
    "# Extract the required columns for training and testing\n",
    "x_train = filtered_df.loc[:, 'CDH']\n",
    "y_train = filtered_df.loc[:, 'MW']\n",
    "t_train = filtered_df['Time']  # Time for training data\n",
    "testing_end_time = pd.Timestamp('2022-10-15 23:00:00+00:00')\n",
    "# For testing data, you might want to use data after end_time\n",
    "testing_mask = (df['Time'] > end_time) & (df['Time'] <= testing_end_time) & (df['CDH'] > 0)\n",
    "testing_df = df[testing_mask]\n",
    "testing_df = testing_df.dropna(subset=['CDH'])\n",
    "testing_df = testing_df.dropna(subset=['MW'])\n",
    "x_test = testing_df.loc[:, 'CDH']\n",
    "y_test = testing_df.loc[:, 'MW']\n",
    "t_test = testing_df['Time']  # Time for testing data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''f,ax = plt.subplots(figsize=(30,6))\n",
    "\n",
    "#plt.plot(df['temperature'], df['MW'])\n",
    "plt.scatter(x_test,y_test,color='red')\n",
    "ax.set_title('x test vs y test')\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "x_train = x_train.values.reshape(-1, 1)\n",
    "x_test = x_test.values.reshape(-1, 1)\n",
    "rmses = []\n",
    "degrees = np.arange(1, 10)\n",
    "min_rmse, min_deg = 1e10, 0\n",
    "\n",
    "for deg in degrees:\n",
    "\n",
    "    # Train features\n",
    "    poly_features = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    x_poly_train = poly_features.fit_transform(x_train)\n",
    "\n",
    "    # Linear regression\n",
    "    poly_reg = LinearRegression()\n",
    "    poly_reg.fit(x_poly_train, y_train)\n",
    "\n",
    "    # Compare with test data\n",
    "    x_poly_test = poly_features.fit_transform(x_test)\n",
    "    poly_predict = poly_reg.predict(x_poly_test)\n",
    "    poly_mse = mean_squared_error(y_test, poly_predict)\n",
    "    poly_rmse = np.sqrt(poly_mse)\n",
    "    rmses.append(poly_rmse)\n",
    "\n",
    "    # Cross-validation of degree\n",
    "    if min_rmse > poly_rmse:\n",
    "        min_rmse = poly_rmse\n",
    "        min_deg = deg\n",
    "\n",
    "# Plot and present results\n",
    "print('Best degree {} with RMSE {}'.format(min_deg, min_rmse))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(degrees, rmses)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Degree')\n",
    "ax.set_ylabel('RMSE')\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "8"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train = pd.to_numeric(x_train, errors='coerce')\n",
    "x_train = x_train.values.reshape(-1, 1)\n",
    "y_train = np.array(y_train)\n",
    "# Linear regression\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(x_train, y_train)\n",
    "\n",
    "predictions = poly_reg.predict(x_train)\n",
    "coef_cooling = poly_reg.coef_\n",
    "CDHmodelScore = poly_reg.score(x_train,y_train)\n",
    "\n",
    "print(\"score of the model is \", CDHmodelScore)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.scatter(x_train, y_train, color='blue', label='Actual MW')\n",
    "\n",
    "# Create a line plot for predictions against x_train\n",
    "plt.scatter(x_train, predictions, color='red', label='Predicted MW')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('x_train')\n",
    "plt.ylabel('MW')\n",
    "plt.title('Actual vs Predicted MW (using only CDH values to predict)')\n",
    "plt.legend()  # Show legend\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coef_cooling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "9"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = df.loc[:,'Temperature':'omega168']\n",
    "X"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "training_mask = (df['Time'] >= start_time) & (df['Time'] <= end_time)\n",
    "\n",
    "#Linear regression for the rest of the model\n",
    "\n",
    "x_behavior = df.loc[:,'omega1':'omega168'][training_mask]\n",
    "y = pd.DataFrame(df['MW'][training_mask])\n",
    "\n",
    "yhat_c = (coef_cooling*df.loc[:,'CDH'][training_mask].values).reshape(-1,1)\n",
    "\n",
    "y_behavior = y - (yhat_c)\n",
    "\n",
    "# Drop rows where y_behavior has NaN values\n",
    "y_behavior = y_behavior.dropna()\n",
    "\n",
    "# Get the index of non-null values in y_behavior and use it to filter x_behavior\n",
    "non_null_index = y_behavior.index\n",
    "x_behavior_filtered = x_behavior.loc[non_null_index]\n",
    "x_behavior= x_behavior_filtered\n",
    "\n",
    "\n",
    "\n",
    "time = df['Time'][training_mask]\n",
    "\n",
    "## ------ fit the behavior model -----\n",
    "model = LinearRegression(fit_intercept=False, positive=True)\n",
    "model.verbose=False\n",
    "model.fit(x_behavior.values,y_behavior.values)\n",
    "#model.coef_,model.intercept_\n",
    "behavior_modelScore = model.score(x_behavior.values,y_behavior.values)\n",
    "print('score of the behavior model is '+str(behavior_modelScore))\n",
    "#predict:\n",
    "yhat_behavior = model.predict(x_behavior.values)\n",
    "\n",
    "\n",
    "\n",
    "# Combine time index and y_behavior values into a new DataFrame\n",
    "predicted_data = pd.DataFrame({'Time': time, 'Predicted MW': yhat_behavior.reshape(-1)})\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.scatter(predicted_data['Time'], predicted_data['Predicted MW'], color='red', label='Predicted MW')\n",
    "plt.scatter(predicted_data['Time'], y_behavior.values, color='blue', label='Actual MW')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MW')\n",
    "plt.title('Actual vs Predicted MW (using behavior model)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "'''\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.scatter(time, y_behavior.values, color='blue', label='Actual MW')\n",
    "plt.scatter(time, yhat_behavior, color='red', label='Predicted MW')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('MW')\n",
    "plt.title('Actual vs Predicted MW (using behavior model)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''\n",
    "#compute the normalized 1-norm based prediction error\n",
    "# -- in sample\n",
    "'''\n",
    "junk = yhat_behavior - y_behavior.loc[:].to_numpy().reshape(-1,1)\n",
    "e_behavior = np.linalg.norm(junk,ord=1)/np.linalg.norm(y_behavior,ord=1)\n",
    "'''\n",
    "#save for later\n",
    "model_behavior = model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_behavior.coef_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" dangerous stuff being done here: manually construct a ful LR model\"\"\"\n",
    "# the dataframe holding X has [T_heat, T_cool, omegas....]\n",
    "c = np.concatenate((np.array([coef_cooling]).reshape(1,-1),\n",
    "                    model_behavior.coef_),axis=1)\n",
    "model_1 = LinearRegression(fit_intercept=False)\n",
    "model_1.coef_ = c\n",
    "model_1.intercept_ = 0\n",
    "\n",
    "# predict using the complete model. We can also add the components already\n",
    "# computedm btu this is cleaner (ideally should compare the two!)\n",
    "\n",
    "X = df.loc[:,'CDH':'omega168']\n",
    "y = pd.DataFrame(df['MW'])\n",
    "time = df.loc[:,'Time']\n",
    "\n",
    "y = y.dropna()\n",
    "X = X.loc[y.index]\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "# Update time based on filtered y\n",
    "time = df.loc[y.index, 'Time']\n",
    "yhat = model_1.predict(X.values)\n",
    "fullmodelScore = model_1.score(X,y)\n",
    "print ('score for constructed full model: ', fullmodelScore)\n",
    "\"\"\"\n",
    "#compute the normalized 1-norm based prediction error\n",
    "# -- in sample\n",
    "junk = yhat - y.loc[:].to_numpy().reshape(-1,1)\n",
    "e_model1 = np.linalg.norm(junk,ord=1)/np.linalg.norm(y,ord=1)\n",
    "\"\"\"\n",
    "\n",
    "# prediction for the full model\n",
    "# yhat = yhat_bahavior+(yhat_c+yhat_h)\n",
    "# against time\n",
    "fig,(ax1) = plt.subplots(nrows=1,figsize=(10,9))\n",
    "_=ax1.plot(time,y,label='meas')\n",
    "_=ax1.plot(time,yhat,label='pred: behavior+heat/cool')\n",
    "ax1.set_title('measured vs predicted data (full constructed model)')\n",
    "_=ax1.legend()\n",
    "\n",
    "'''\n",
    "print('+++++ for model 1, constructed with heat/cool/behavior done separately and then joined++++:')\n",
    "print('1 norm of the normalized pred error with the training data ='+str(e_model1))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = y.dropna()\n",
    "X = X.loc[y.index]\n",
    "\n",
    "# Update time based on filtered y\n",
    "time = df.loc[y.index, 'Time']\n",
    "has_nan_X = X.isna().any().any()\n",
    "\n",
    "# For Series y\n",
    "has_nan_y = y.isna().any()\n",
    "\n",
    "print(\"X contains NaN values: \", has_nan_X)\n",
    "print(\"y contains NaN values: \", has_nan_y)\n",
    "# Drop NaN values from y and corresponding rows from X\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "## ------- model version 2------\n",
    "## Full model in one shot, like in the past\n",
    "\n",
    "## ------ fit the model -----\n",
    "model_2 = LinearRegression(fit_intercept=False)\n",
    "model_2.verbose=False\n",
    "model_2.fit(X.values,y.values)\n",
    "\n",
    "#model.coef_,model.intercept_\n",
    "modelScore = model_2.score(X.values,y.values)\n",
    "print('score of the full, one shot, model is '+str(modelScore))\n",
    "#predict:\n",
    "yhat = model_2.predict(X.values)\n",
    "filtered_cdh = df.loc[y.index, 'CDH']\n",
    "#compute the normalized 1-norm based prediction error\n",
    "# -- in sample\n",
    "junk = yhat - y.loc[:].to_numpy().reshape(-1,1)\n",
    "e_model2 = np.linalg.norm(junk,ord=1)/np.linalg.norm(y,ord=1)\n",
    "\n",
    "# prediction for the full model\n",
    "# against time\n",
    "fig,(ax1,ax2) = plt.subplots(nrows=2,figsize=(10,9))\n",
    "ax1.set_title(label='Results for the one-shot model')\n",
    "_=ax1.plot(time,y,label='meas')\n",
    "_=ax1.plot(time,yhat,label='pred')\n",
    "_=ax1.legend()\n",
    "#against tcool and t heat to see if the slope is better?\n",
    "_=ax2.scatter(filtered_cdh,y,label='demand vs. CDH')\n",
    "_=ax2.scatter(filtered_cdh,yhat,label='pred vs. CDH')\n",
    "_=ax2.legend()\n",
    "\n",
    "\n",
    "print('+++++ for model 2, constructed in one shot')\n",
    "print('1 norm of the normalized pred error with the training data ='+str(e_model2))\n",
    "'''\n",
    "'''\n",
    "print('------ the coef for Theat and T-cool for the one-shot model = ')\n",
    "c = model_2.coef_\n",
    "\n",
    "print('alpha - cool = '+str(c))\n",
    "print('------ the coef for Theat and T-cool for the one at a time model = ')\n",
    "\n",
    "print('alpha - cool = '+str(coef_cooling))\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "me_array = np.array(filtered_df['MW'], dtype='float64')\n",
    "temp_array = np.array(filtered_df['Temperature'], dtype='float64')\n",
    "correlation_coefficient = np.corrcoef(me_array, temp_array)[0, 1]\n",
    "print(correlation_coefficient)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#------------------ predict for the whole data set:\n",
    "XAll=df.loc[:,'CDH':'omega168']\n",
    "yAll=pd.DataFrame(df.loc[:,'MW'])\n",
    "timeAll=df['Time']#Series object\n",
    "\n",
    "\n",
    "\n",
    "def f_getYhatDataFrame(df,model):\n",
    "    #prediction by model 1\n",
    "    XAll=df.loc[:,'CDH':'omega168']\n",
    "    yAll=pd.DataFrame(df.loc[:,'MW'])\n",
    "    yAll = yAll.dropna()\n",
    "    XAll = XAll.loc[y.index]\n",
    "\n",
    "    # Update time based on filtered y\n",
    "    timeAll = df.loc[y.index, 'Time']\n",
    "\n",
    "    yAllhat = pd.DataFrame(model_1.predict(XAll.values),columns=['MW'])\n",
    "\n",
    "    scAll = model.score(XAll.values,yAll.values)\n",
    "\n",
    "    cs = model.coef_\n",
    "\n",
    "\n",
    "\n",
    "    c = cs\n",
    "    yy = df['CDH'] * pd.Series(c.reshape(-1,))\n",
    "    yAllhat_cool = pd.DataFrame(yy.values,columns=['MW'])\n",
    "\n",
    "    #save predictions from the fitted model\n",
    "    XAllNoTempr=XAll.copy()\n",
    "\n",
    "    XAllNoTempr['CDH'] = np.zeros((XAllNoTempr.shape[0],1))\n",
    "    yAll_hat_NoTempr = pd.DataFrame(model.predict(XAllNoTempr.values),columns=['MW'])\n",
    "\n",
    "    junk = [df[['Time','MW']],yAllhat,yAllhat_cool,yAll_hat_NoTempr,df[['CDH']]]\n",
    "    dfOut = pd.concat(junk,axis=1)\n",
    "    return dfOut,scAll\n",
    "\n",
    "\n",
    "df_yhatEtc_model1,sc1 = f_getYhatDataFrame(df,model_1)\n",
    "print('score for prediction of all data with model 1 is = '+str(sc1))\n",
    "#df_yhatEtc_model1.head()\n",
    "#-------- repeat for model 2 ----\n",
    "'''\n",
    "df_yhatEtc_model2,sc2 = f_getYhatDataFrame(df,model_2)\n",
    "print('score for prediction of all data with model 2 is = '+str(sc2))\n",
    "df_yhatEtc_model2.head()\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''printfigs=1\n",
    "years = ('2018','2019','2020')\n",
    "for year in years:\n",
    "    t1 = f_time2Eastern(firstMondayMarch[year].iloc[0])\n",
    "    t2 = t1+datetime.timedelta(days=30)\n",
    "    mask = (df_yhatEtc_model1['DateTime']>=t1)&(df_yhatEtc_model1['DateTime']<=t2)\n",
    "\n",
    "    fig,ax = plt.subplots(ncols=1, figsize=(20,5))\n",
    "    plt.subplots_adjust(bottom=.25)\n",
    "\n",
    "    _=ax.plot(df_yhatEtc_model1['DateTime'][mask],df_yhatEtc_model1['Demand (MWh)'][mask],color='blue',label='measured')\n",
    "    _=ax.plot(df_yhatEtc_model1['DateTime'][mask],df_yhatEtc_model1['Demand-pred (MWh)'][mask],color='magenta',linestyle='--',label='predicted')\n",
    "    #_=ax.plot(df_yhatEtc_model2['DateTime'][mask],df_yhatEtc_model2['Demand-pred (MWh)'][mask],color='brown',linestyle='--',label='predicted, model 2')\n",
    "    _=plt.legend()\n",
    "    _=ax.set_ylim(125, 350)\n",
    "    ax.set_ylabel('Hourly energy use (MWh)')\n",
    "    locator = mpl.dates.AutoDateLocator(minticks=7, maxticks=12)\n",
    "    #formatter = mpl.dates.ConciseDateFormatter(locator)\n",
    "    formatter = mpl.dates.DateFormatter('%a %d\\n %m-%y')\n",
    "    ax.xaxis.set_major_locator(locator)\n",
    "    ax.xaxis.set_major_formatter(formatter)\n",
    "    ax.grid()\n",
    "    ax.set_xlim(t1,t2)\n",
    "    _=ax.legend()\n",
    "    sns.set_context(\"paper\", font_scale=2.5, rc={\"lines.linewidth\": 1.5})\n",
    "\n",
    "    bbox_props = dict(boxstyle=\"round\", fc=\"w\", ec=\"0.5\", facecolor=\"0.1\", alpha=0.5)\n",
    "    ax.text(t1+datetime.timedelta(days=15), 325, year, ha=\"center\", va=\"center\", size=20,\n",
    "        bbox=bbox_props)\n",
    "\n",
    "    figname = 'demandPredHourly_'+year+'March_fit2019_'+TmprModel+'.pdf'\n",
    "    if printfigs:\n",
    "        fig.savefig('../Figures/forPaper/fromRegression/'+figname)\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_df = df.dropna()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mw_array = np.array(new_df['MW'], dtype='float64')\n",
    "temp_array = np.array(new_df['CDH'], dtype='float64')\n",
    "correlation_coefficient = np.corrcoef(mw_array, temp_array)[0, 1]\n",
    "print(correlation_coefficient)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "me_array = np.array(new_df['MW'], dtype='float64')\n",
    "temp_array = np.array(new_df['Temperature'], dtype='float64')\n",
    "correlation_coefficient = np.corrcoef(me_array, temp_array)[0, 1]\n",
    "print(correlation_coefficient)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "hours = df['Time'].dt.hour\n",
    "\n",
    "df_12am_to_6am = df[(hours >= 0) & (hours <= 6)]\n",
    "\n",
    "df_excluding_12am_to_6am = df[(hours < 0) | (hours > 6)]\n",
    "df_excluding_12am_to_6am.dropna(inplace= True)\n",
    "\n",
    "df_12am_to_6am.dropna(inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "me_array = np.array(df_12am_to_6am['MW'], dtype='float64')\n",
    "temp_array = np.array(df_12am_to_6am['Temperature'], dtype='float64')\n",
    "correlation_coefficient = np.corrcoef(me_array, temp_array)[0, 1]\n",
    "print('between 12am to 6am: ',correlation_coefficient)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "me_array = np.array(df_excluding_12am_to_6am['MW'], dtype='float64')\n",
    "temp_array = np.array(df_excluding_12am_to_6am['Temperature'], dtype='float64')\n",
    "correlation_coefficient = np.corrcoef(me_array, temp_array)[0, 1]\n",
    "print('excluding 12am to 6am: ',correlation_coefficient)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_12am_to_6am.index, df_12am_to_6am['MW'], marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MW')\n",
    "plt.title('MW vs Time (12:00 AM to 6:00 AM)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df_excluding_12am_to_6am.index, df_excluding_12am_to_6am['MW'], marker='o', linestyle='-', color='g')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('MW')\n",
    "plt.title('MW vs Time (excluding 12:00 AM to 6:00 AM)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
