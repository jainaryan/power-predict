{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "import re\n",
    "import matplotlib\n",
    "from matplotlib.patches import Polygon, Rectangle\n",
    "matplotlib.use('Qt5Agg')\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from casadi import *\n",
    "import calendar\n",
    "import casadi as cd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the bill data and the power data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def custom_date_parser(date_string):\n",
    "    return pd.to_datetime(date_string, format='%d-%m-%Y %H:%M:%S')\n",
    "\n",
    "# Specify the path to the main directory containing folders and files\n",
    "path = 'D:\\\\mlinternship\\\\iitgdata'\n",
    "folders = [folder for folder in os.listdir(path) if os.path.isdir(os.path.join(path, folder))]\n",
    "df_list = []\n",
    "\n",
    "# Iterate through each folder\n",
    "for folder in folders:\n",
    "    # Construct the full path to the current folder\n",
    "    folder_path = os.path.join(path, folder)\n",
    "    # Iterate through files in the current folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file has the '.xlsx' extension\n",
    "        if filename.endswith('.xlsx'):\n",
    "            # Construct the full path to the Excel file\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Use the custom date parser function\n",
    "            df = pd.read_excel(file_path, header=3, date_parser=custom_date_parser)\n",
    "            # Append the dataframe to the list\n",
    "            df_list.append(df)\n",
    "\n",
    "bill_path = 'D:\\\\mlinternship\\\\IITGuwahatiElectricityBills'\n",
    "for filename in os.listdir(bill_path):\n",
    "    # Check if the file has the '.xlsx' extension\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(bill_path, filename)\n",
    "        # Use the custom date parser function\n",
    "        bill_df = pd.read_excel(file_path)\n",
    "\n",
    "bill_df['Month'] = pd.to_datetime(bill_df['Month'])\n",
    "#I assumed its in kilowatts\n",
    "bill_df['MW'] = bill_df['Number of units of electricity consumed']/1000\n",
    "bill_df.drop(['Number of units of electricity consumed'], axis=1)\n",
    "bill_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reading the temperature data and merging the power and temperature data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#read the power data\n",
    "power_df = pd.concat(df_list, ignore_index=True)\n",
    "power_df.to_csv('power_datacsv.csv')\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'])\n",
    "power_df['Time'] = power_df['Time'].round('min')\n",
    "#replace all the 'NR' values in MW column to NaN\n",
    "power_df['MW'] = power_df['MW'].replace('NR', np.nan)\n",
    "power_df['MW'] = power_df['MW'].replace('nr', np.nan)\n",
    "power_df = power_df[['Time', 'MW']]\n",
    "power_df['MW'] = power_df['MW'].astype(str)\n",
    "power_df['MW'] = pd.to_numeric(power_df['MW'].str.replace(',', '.'), errors='coerce')\n",
    "power_df['Time'] = pd.to_datetime(power_df['Time'])\n",
    "power_df = power_df.sort_values('Time')\n",
    "full_power_df = power_df.copy()\n",
    "\n",
    "# read the temperature data csv\n",
    "temperature_data_csv_path = 'D:\\\\mlinternship\\\\iitgdata\\\\temperaturedata'\n",
    "filename = 'guwahati_temperature_data.csv'\n",
    "file = os.path.join(temperature_data_csv_path, filename)\n",
    "temperature_df = pd.read_csv(file)\n",
    "temperature_df.rename(columns={'valid': 'Time'}, inplace = True)\n",
    "temperature_df = temperature_df.rename(columns={'tmpc': 'temperature'})\n",
    "temperature_df = temperature_df[['Time', 'temperature']]\n",
    "temperature_df['Time'] = pd.to_datetime(temperature_df['Time'])\n",
    "temperature_df['Time'] = pd.DatetimeIndex(temperature_df['Time']) + timedelta(hours=5,minutes=30)\n",
    "temperature_df['temperature'] = pd.to_numeric(temperature_df['temperature'], errors='coerce')\n",
    "temperature_df.set_index('Time', inplace=True)\n",
    "temperature_df['temperature'] = temperature_df['temperature'].interpolate(method='polynomial', order = 5)\n",
    "temperature_df.reset_index(inplace=True)\n",
    "\n",
    "# joining the two dataframes such that the temperature data is only taken if there exists a reading in the power data dataframe\n",
    "df = pd.merge(power_df, temperature_df, on='Time', how='left')\n",
    "df['temperature'] = df['temperature'].interpolate(method='polynomial', order = 5)\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "\n",
    "full_model_start_time = pd.Timestamp('2022-02-07 00:00:00')\n",
    "full_model_end_time = pd.Timestamp('2022-12-25 23:00:00')\n",
    "df = df[(df['Time'] >= full_model_start_time) & (df['Time'] <= full_model_end_time)]\n",
    "df = df.drop(df[df['MW'] > 20].index)\n",
    "df = df.sort_values('Time')\n",
    "df.reset_index(drop=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating the CDH and Omega columns"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TcoolStPt = 31\n",
    "CDH = df['temperature'] - TcoolStPt\n",
    "CDH.clip(lower=0, inplace=True)\n",
    "CDH = pd.DataFrame(data=CDH.values, columns=['CDH'], index=df.index)\n",
    "# Concatenate CDH with the original DataFrame using the index\n",
    "df = pd.concat([df, CDH], axis=1)\n",
    "df = df.sort_values('Time')\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "\n",
    "numOmegas = 24 * 7\n",
    "num_of_rows = df.shape[0]\n",
    "omegas = np.zeros((num_of_rows, numOmegas))  # Assuming numOmegas columns for omegas\n",
    "concatenated_data = np.concatenate((df, omegas), axis=1)\n",
    "column_names = ['Time', 'MW', 'temperature', 'CDH']\n",
    "for i in range(1, numOmegas + 1,1):\n",
    "    column_names.append('omega' + str(i))\n",
    "\n",
    "df = pd.DataFrame(concatenated_data, columns=column_names)\n",
    "df['Time'] = pd.to_datetime(df['Time'])\n",
    "for i in range(0,num_of_rows):\n",
    "        datetime = df.Time.loc[i]\n",
    "        hourOfWeekIndex = int(datetime.dayofweek*24+(datetime.hour+1))\n",
    "        x = np.zeros((1,numOmegas))\n",
    "        x[0,hourOfWeekIndex-1]=1\n",
    "        omegas[i,:]=x\n",
    "\n",
    "df.iloc[:,4:]=omegas\n",
    "DF = df.copy()\n",
    "df = df.dropna()\n",
    "df.reset_index(inplace=True, drop = True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "start_time = pd.Timestamp('2022-07-04 00:00:00')\n",
    "end_time = pd.Timestamp('2022-08-28 23:00:00')\n",
    "training_mask = (df['Time'] >= start_time) & (df['Time'] <= end_time) & (df['CDH'] > 0)\n",
    "df = df[training_mask]'''"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "doing the optimization in one shot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#tried to do the temperature and behavior part together\n",
    "start_time = pd.Timestamp('2022-08-01 00:00:00')\n",
    "end_time = pd.Timestamp('2022-08-28 23:00:00')\n",
    "\n",
    "training_mask = (df['Time'] >= start_time) & (df['Time'] <= end_time)\n",
    "training_df = df[training_mask]\n",
    "d = training_df.loc[:,'MW']\n",
    "phi_temperature = training_df.loc[:,'CDH']\n",
    "phi_behavior = training_df.loc[:,'omega1':'omega168']\n",
    "opti = cd.Opti()\n",
    "temperature_theta = opti.variable()\n",
    "behavior_theta = opti.variable(168)\n",
    "total_sum =0\n",
    "for i in range (0,len(d)):\n",
    "    phi_behavior_i = (cd.MX(phi_behavior.iloc[i].values))\n",
    "    phi_behavior_i =  cd.vertcat(phi_behavior_i)\n",
    "    residual = (d.iloc[i] - ((phi_temperature.iloc[i] * temperature_theta) + cd.dot(phi_behavior_i, behavior_theta)))**2\n",
    "    total_sum += residual\n",
    "\n",
    "opti.subject_to(temperature_theta >= 0)\n",
    "e1 = 3.0\n",
    "e2 = 3.0\n",
    "\n",
    "for i in range(0, 167):\n",
    "    opti.subject_to((behavior_theta[i + 1] - behavior_theta[i]) <= e1)\n",
    "    opti.subject_to((behavior_theta[i + 1] - behavior_theta[i]) >= -e1)\n",
    "    opti.subject_to(behavior_theta[i] >= 0)\n",
    "    opti.subject_to(behavior_theta[i] <= 7)\n",
    "\n",
    "for i in range(1, 167):\n",
    "    opti.subject_to((behavior_theta[i + 1] + behavior_theta[i - 1] - 2 * behavior_theta[i]) <= e2)\n",
    "    opti.subject_to((behavior_theta[i + 1] + behavior_theta[i - 1] - 2 * behavior_theta[i]) >= -e2)\n",
    "\n",
    "#this bill part is kind of hardcoded rn\n",
    "for i in range(7,8):\n",
    "    month = bill_df.iloc[i]['Month'].month\n",
    "    year = bill_df.iloc[i]['Month'].year\n",
    "    num_days = calendar.monthrange(year, month)[1]\n",
    "    first_day = calendar.monthrange(year, month)[0]\n",
    "    num_hours = num_days * 24\n",
    "    num_weeks = num_hours / 168.0\n",
    "    weekly_behavior_energy_use = 0\n",
    "    temperature_energy_use = 0\n",
    "    for j in range(len(training_df)):\n",
    "        temperature_energy_use += temperature_theta * training_df.iloc[j]['CDH']\n",
    "\n",
    "    for j in range(0, 168):\n",
    "        weekly_behavior_energy_use += behavior_theta[j]\n",
    "    weekly_energy_use = weekly_behavior_energy_use +  temperature_energy_use\n",
    "    opti.subject_to(weekly_energy_use < 1.5 * bill_df.iloc[i]['MW'] / num_weeks)\n",
    "    opti.subject_to(weekly_energy_use > 0.5 * bill_df.iloc[i]['MW'] / num_weeks)\n",
    "\n",
    "# Solve the optimization problem\n",
    "opti.minimize(total_sum)\n",
    "solver_opts = {'print_time': 0}\n",
    "opti.solver('ipopt', solver_opts)\n",
    "sol = opti.solve()\n",
    "\n",
    "optimal_temperature_theta = sol.value(temperature_theta)\n",
    "optimal_behavior_theta = sol.value(behavior_theta)\n",
    "print(\"Optimal value of temperature_theta:\", optimal_temperature_theta)\n",
    "print(\"Optimal values of theta:\", optimal_behavior_theta)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#final model with df(even null values)\n",
    "training_df = df[training_mask]\n",
    "d = training_df['MW']\n",
    "c = np.concatenate((np.array([optimal_temperature_theta]),optimal_behavior_theta),axis=0)\n",
    "phi =training_df.loc[:,'CDH':'omega168']\n",
    "full_model = LinearRegression(fit_intercept=False)\n",
    "full_model.fit(phi, d)\n",
    "full_model.coef_ = c\n",
    "full_model.intercept_ = 0\n",
    "yhat = full_model.predict(phi.values)\n",
    "full_modelScore = full_model.score(phi,d)\n",
    "\n",
    "print ('score for constructed full model on full data: ', full_modelScore)\n",
    "fig,(ax2) = plt.subplots(nrows=1,figsize=(10,9))\n",
    "_=ax2.plot(training_df['Time'],d,label='meas', marker = 'o')\n",
    "_=ax2.plot(training_df['Time'],yhat,label='pred:', marker = 'x')\n",
    "ax2.set_title('measured vs predicted data (full constructed model) (only for non null values)')\n",
    "_=ax2.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "actual vs predicted data with graph shading"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#graph with shaded portion to represent missing values\n",
    "\n",
    "#final model with DF\n",
    "training_mask = (DF['Time'] >= start_time) & (DF['Time'] <= end_time)\n",
    "training_df = DF[training_mask]\n",
    "#actual_data = training_df['MW'].dropna()\n",
    "training_df['MW'] = training_df['MW'].replace(np.nan, 0)\n",
    "d = training_df['MW']\n",
    "c = np.concatenate((np.array([optimal_temperature_theta]),optimal_behavior_theta),axis=0)\n",
    "phi =training_df.loc[:,'CDH':'omega168']\n",
    "yhat = full_model.predict(phi.values)\n",
    "actual_df = DF.copy()\n",
    "actual_df = actual_df[training_mask]\n",
    "actual_df.dropna(inplace = True)\n",
    "\n",
    "fig10,(ax10) = plt.subplots(nrows=1,figsize=(10,9))\n",
    "first_time = True\n",
    "j = 0\n",
    "\n",
    "for i in range(1, len(training_df)):\n",
    "    if (j < len(actual_df)) and (training_df.iloc[i]['Time'] == actual_df.iloc[j]['Time']):\n",
    "        j+=1\n",
    "    else:\n",
    "        iterator = i\n",
    "        last_iterator = i-1\n",
    "        first_time= False\n",
    "        start =  mdates.date2num(training_df.iloc[last_iterator]['Time'])\n",
    "        end =  mdates.date2num(training_df.iloc[iterator]['Time'])\n",
    "        print(f'index: {i} start:{start}, width:{end-start}')\n",
    "        rect = Rectangle((start, 0), end-start, 10, linewidth=1,  facecolor='green', alpha = 0.2, zorder = 10)\n",
    "        ax10.add_patch(rect)\n",
    "\n",
    "locator = mdates.AutoDateLocator(minticks=3)\n",
    "formatter = mdates.AutoDateFormatter(locator)\n",
    "ax10.xaxis.set_major_locator(locator)\n",
    "ax10.xaxis.set_major_formatter(formatter)\n",
    "_=ax10.plot(actual_df['Time'][training_mask],actual_df[training_mask]['MW'],label='meas', marker = 'o', color = 'r', zorder = 5)\n",
    "_=ax10.plot(training_df['Time'][training_mask],yhat,label='pred:', marker = 'x', color = 'y', zorder = 5)\n",
    "ax10.set_title('measured vs predicted data (full constructed model with NA)')\n",
    "_=ax10.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#final model with DF\n",
    "training_mask = (DF['Time'] >= start_time) & (DF['Time'] <= end_time)\n",
    "training_df = DF[training_mask]\n",
    "#actual_data = training_df['MW'].dropna()\n",
    "training_df['MW'] = training_df['MW'].replace(np.nan, 0)\n",
    "d = training_df['MW']\n",
    "c = np.concatenate((np.array([optimal_temperature_theta]),optimal_behavior_theta),axis=0)\n",
    "phi =training_df.loc[:,'CDH':'omega168']\n",
    "yhat = full_model.predict(phi.values)\n",
    "actual_df = DF.copy()\n",
    "actual_df = actual_df[training_mask]\n",
    "actual_df.dropna(inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "fig10,(ax10) = plt.subplots(nrows=1,figsize=(10,9))\n",
    "first_time = True\n",
    "for i in range(0, len(actual_df)):\n",
    "    if training_df.iloc[iterator+1]['Time'] == actual_df.iloc[i]['Time']:\n",
    "        pass\n",
    "    else:\n",
    "        iterator = i\n",
    "        while (training_df.iloc[iterator]['Time']!= actual_df.iloc[i]['Time']):\n",
    "            iterator+=1\n",
    "            if (iterator > len(actual_df)-1):\n",
    "                iterator-=1\n",
    "                break\n",
    "        if first_time == True:\n",
    "            last_iterator = i\n",
    "            first_time= False\n",
    "\n",
    "        start = training_df.iloc[last_iterator]['Time']\n",
    "        width = training_df.iloc[iterator]['Time'] - training_df.iloc[last_iterator]['Time']\n",
    "        rect = Rectangle((start, 0), width, 10, linewidth=1,  facecolor='green', alpha = 0.2, zorder = 10)\n",
    "        ax10.add_patch(rect)\n",
    "        last_iterator = iterator\n",
    "\n",
    "_=ax10.plot(actual_df['Time'][training_mask],actual_df[training_mask]['MW'],label='meas', marker = 'o', color = 'r', zorder = 5)\n",
    "_=ax10.plot(training_df['Time'][training_mask],yhat,label='pred:', marker = 'x', color = 'y', zorder = 5)\n",
    "ax10.set_title('measured vs predicted data (full constructed model with NA)')\n",
    "_=ax10.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#final model with DF\n",
    "training_mask = (DF['Time'] >= start_time) & (DF['Time'] <= end_time)\n",
    "training_df = DF[training_mask]\n",
    "training_df['MW'] = training_df['MW'].replace(np.nan, 0)\n",
    "phi = training_df.loc[:, 'CDH':'omega168']\n",
    "yhat = full_model.predict(phi.values)\n",
    "actual_df = DF.copy()\n",
    "actual_df = actual_df[training_mask]\n",
    "actual_df.dropna(inplace=True)\n",
    "\n",
    "# Reset indices for both training_df and actual_df\n",
    "training_df.reset_index(drop=True, inplace=True)\n",
    "actual_df.reset_index(drop=True, inplace=True)\n",
    "fig10, (ax10) = plt.subplots(nrows=1, figsize=(10, 9))\n",
    "\n",
    "# Reset indices for consistency\n",
    "training_df_reset = training_df.reset_index(drop=True)\n",
    "actual_df_reset = actual_df.reset_index(drop=True)\n",
    "\n",
    "# Initialize variables to track the start of mismatched regions\n",
    "start_idx = 0\n",
    "\n",
    "# Iterate through timestamps and plot rectangles for the mismatched regions\n",
    "for i in range(len(actual_df_reset)):\n",
    "    if training_df_reset['Time'][i] != actual_df_reset['Time'][i]:\n",
    "        # End of mismatched region, plot a rectangle\n",
    "        end_idx = i\n",
    "        rect = Rectangle((start_idx, 0), end_idx - start_idx, 10, linewidth=1, facecolor='green', alpha=0.7, zorder=10)\n",
    "        ax10.add_patch(rect)\n",
    "        start_idx = i + 1  # Update start index for the next region\n",
    "\n",
    "# Plot the actual and predicted data\n",
    "_=ax10.plot(actual_df_reset['Time'], actual_df_reset['MW'], label='meas', marker='o', color='r', zorder=5)\n",
    "_=ax10.plot(training_df_reset['Time'], yhat, label='pred:', marker='x', color='y', zorder=5)\n",
    "\n",
    "ax10.set_title('measured vs predicted data (full constructed model with NA)')\n",
    "_=ax10.legend()\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "PRCATICE\n",
    "x = SX.sym(\"x\",3)\n",
    "f = x[0]**2 + x[1]**2 + x[2]**2\n",
    "g1 = cd.fabs(x[2] - x[1]) - 1\n",
    "g2 = cd.fabs(x[1] - x[0]) - 1\n",
    "g3 = x[0] + x[1] + x[2] - 5\n",
    "g4 = x[0]\n",
    "g5 = x[1]\n",
    "g6 = x[2]\n",
    "g = cd.vertcat(g1,g2,g3,g4,g5,g6)\n",
    "nlp = {'x': x, 'f': f, 'g': g}\n",
    "MySolver = 'ipopt'\n",
    "opts = {}\n",
    "# Allocate a solver\n",
    "solver = nlpsol(\"solver\", MySolver, nlp, opts)\n",
    "# Solve the NLP\n",
    "lbg = [0,0,0, 0,0,0]\n",
    "ubg = [inf, inf,5,inf,inf,inf]\n",
    "sol = solver(lbg=lbg, ubg=ubg)\n",
    "# Print solution\n",
    "print(\"-----\")\n",
    "print(\"objective at solution = \", sol[\"f\"])\n",
    "print(\"primal solution = \", sol[\"x\"])\n",
    "print(\"dual solution (x) = \", sol[\"lam_x\"])\n",
    "print(\"dual solution (g) = \", sol[\"lam_g\"])\n",
    "'''\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
